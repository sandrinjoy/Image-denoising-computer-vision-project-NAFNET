% This version of CVPR template is provided by Ming-Ming Cheng.
% Please leave an issue if you found a bug:
% https://github.com/MCG-NKU/CVPR_Template.

\documentclass[final]{article}

\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{placeins}

% Include other packages here, before hyperref.
\usepackage{blindtext}


% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false]{hyperref}



\def\confYear{3D Reconstruction Final Project \the\year{} Group 10} % Please enter your group number here
\setcounter{page}{1} % For final version only


\begin{document}

%%%%%%%%% please Enter Title here : TITLE
\title{Image Denoising}

\author{Sandrine Pudukkattukaran Joy\\
4743017\\
{\tt\small Data and Computer Science}
\and
Muhammad Sawaiz Khan \\
4750304\\
{\tt\small Data and Computer Science}
}

\maketitle


%%%%%%%%% ABSTRACT
\begin{abstract}
	Image denoising is a fundamental problem in image processing and computer vision that involves the removal of unwanted noise from digital images. Noise can be introduced during image acquisition, transmission, or storage processes and can significantly degrade image quality and alter subsequent analysis tasks. Traditional approaches to image denoising include filtering techniques such as Gaussian filters, median filters, and wavelet-based methods. However, these methods often struggle to preserve fine details and textures while removing noise.
In recent years, deep learning approaches, particularly those based on Convolutional Neural Networks (CNNs) and autoencoders, have shown remarkable performance in image denoising tasks. These approaches learn directly from data and can effectively model complex noise patterns while preserving important image features.

\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}

Image denoising is a foundational task in computer vision, critical for applications ranging from medical imaging to autonomous systems. Traditional methods like Gaussian filtering struggle with complex noise patterns, whereas deep learning models learn noise distributions directly from the data, enabling superior performance.

\subsection{Project Objectives}

\begin{itemize}
    \item Implement a lightweight autoencoder for denoising RGB images.

\item Study the architecture of NAFNet to understand its activation-free design.

\item Benchmark denoising performance for multiple noise types.

\end{itemize}

Dataset: The CIFAR-10 data set was chosen for its RGB complexity and manageable size (60,000 32x32 images), balancing computational feasibility with meaningful feature learning.



%-------------------------------------------------------------------------
\section{Related Work: NAFNet Analysis}

NAFNet (Nonlinear Activation-Free Network) is a leading model in image restoration, notable for its:

1. Activation-Free Design: Replaces ReLU/GELU with element-wise multiplications, reducing computational overhead.

2. Multi-Scale Architecture: Uses a U-Net-like structure with skip connections for parameter efficiency.

3. Performance: Achieves state-of-the-art results on benchmarks like GoPro and CIFAR-10 with fewer parameters.

Key Insights:

- Challenges the necessity of nonlinear activations in deep networks.

- Balances accuracy and efficiency, making it suitable for resource-constrained environments.




\section{Methodology}

%-------------------------------------------------------------------------


\subsection{Data Preparation}

\begin{itemize}
    \item Noise Synthesis \begin{itemize}
            \item Gaussian: Added with $\sigma = 0.2$
            \item Salt \& Pepper: Randomly set pixels to 0 or 1 ($p = 0.02$).
            \item Poisson: Simulated photon-limited noise \end{itemize}
    \item Pre-processing
        \begin{itemize}
            \item Resized images to 64x64 to preserve structural details.
            \item Normalized pixel values to [0, 1].
        \end{itemize}
    \item Data Split
    \begin{itemize}
        \item Training (80\%): 40,000 images.
        \item Validation (20\%): 10,000 images.
        \item Test: 10,000 images.
    \end{itemize}
\end{itemize}

\subsection{Model Architecture}

A convolutional autoencoder with symmetric encoder-decoder layers:
\begin{itemize}
    \item Encoder:
    \begin{itemize}
        \item Two 3x3 convolutional layers (stride=2) reducing spatial dimensions to 32x32.
        \item Channel dimensions: 3 → 16 → 32.
    \end{itemize}
    \item Decoder:
    \begin{itemize}
        \item Transposed convolutions for upsampling.
        \item Channel dimensions: 32 → 16 → 3.
    \end{itemize}
    \item Activation: Sigmoid for output normalization.
\end{itemize}

\subsection{Training Configuration}
\begin{itemize}
    \item Loss: Mean Squared Error (MSE).
    \item Optimizer: Adam ($lr = 0.001$).
    \item Batch Sizes: Tested 256 (32x32) vs. 128 (64x64).
    \item Epochs: 20 (limited by hardware).
    \item Hardware: Apple M2 Pro (16GB RAM) and Google Colab CPUs.
\end{itemize}

\subsection{Evaluation Metrics}
\begin{itemize}
    \item PSNR: Quantified denoising quality.
    \item Visual Comparison: Noisy, denoised, and clean image grids.
\end{itemize}

\subsection{Training Dynamics}
The model showed stable convergence with training loss decreasing from 0.0173 to 0.0056 over 20 epochs (Figure~\ref{fig:loss}). Validation loss followed similar trends, indicating no significant overfitting.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.8\textwidth]{loss_curve.png}
\caption{Training and validation loss progression (MSE) across epochs}
\label{fig:loss}
\end{figure}

\begin{table}[htbp]
\centering
\caption{Loss milestones during training}
\label{tab:loss}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Training Phase} & \textbf{Train Loss} & \textbf{Val Loss} \\
\midrule
Initial (Epoch 1) & 0.0173 & 0.0099 \\
Mid-training (Epoch 10) & 0.0061 & 0.0069 \\
Final (Epoch 20) & 0.0056 & 0.0057 \\
\bottomrule
\end{tabular}
\end{table}


\section{Results}
\subsection{Convergence Analysis}
As shown in Figure~\ref{fig:loss}, the model achieved 90\% of total loss reduction within the first 10 epochs, with subsequent training providing diminishing returns. Table~\ref{tab:loss} quantifies this progression, showing better final validation performance (0.0057) compared to mid-training (0.0069).


\subsection{Training Performance}
    \begin{itemize}
    \item Best Configuration: 64x64 resolution + batch size 128.
    \begin{itemize}
    \item Training Loss: 0.0017 | Validation Loss: 0.0015.
    \item PSNR: 28.33 dB (vs. 22.82 dB for noisy inputs).
    \end{itemize}
    \end{itemize}

\begin{table}[h]
    \centering
    \begin{tabular}{lcccc}
        \hline
        Configuration & Train Loss & Val Loss & PSNR (dB) & Training Time \\
        \hline
        32x32, BS=256 & 0.0056 & 0.0057 & 22.82 & 60 min \\
        64x64, BS=128 & 0.0017 & 0.0015 & 28.33 & 180 min \\
        \hline
    \end{tabular}
    \caption{Training results for different configurations.}
    \label{tab:training_results}
\end{table}

\subsection{Denoising Visualization}
Top: Noisy, Middle: Denoised, Bottom: Clean

\afterpage{\clearpage} % Forces all pending floats (figures) to be placed before continuing
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{test_results.png}
    \caption{Test results}
    \label{fig:image_label}
\end{figure}

\subsection{Noise Generalization}
\begin{table}[h]
    \centering
    \begin{tabular}{|l|c|l|}
        \hline
        \textbf{Noise Type} & \textbf{PSNR (dB)} & \textbf{Visual Quality} \\
        \hline
        Gaussian ($\sigma = 0.2$) & 28.33 & Excellent \\
        Salt \& Pepper & - & Poor \\
        Poisson & - & Moderate \\
        \hline
    \end{tabular}
    \caption{Noise Types and their PSNR and Visual Quality}
    \label{tab:noise_types}
\end{table}
\afterpage{\clearpage} % Forces all pending floats (figures) to be placed before continuing
\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{noise_types_comparison.png}
    \caption{Noise type Comparisons}
    \label{fig:image_label}
\end{figure}

%------------------------------------------------------------------------
\section{Discussion}

\subsection{Key Findings}
\begin{itemize}
    \item \textbf{64x64 Images}: Larger resolutions preserved edges/textures, improving PSNR by 2.3 dB.
    \item \textbf{Batch Size}: Smaller batches (128) enabled frequent weight updates, enhancing convergence.
    \item \textbf{NAFNet Comparison}: NAFNet achieved higher PSNR (~32 dB) but required 10x more parameters.
\end{itemize}

\subsection{Limitations}
\begin{itemize}
    \item \textbf{Noise Specificity}: Model tailored for Gaussian noise; Salt \& Pepper performance lagged.
    \item \textbf{Resolution}: CIFAR-10’s small size limited real-world applicability.
\end{itemize}

\section{Conclusion}
This project demonstrated the efficacy of lightweight autoencoders for image denoising, achieving 28.33 dB PSNR on Gaussian noise. Insights from NAFNet highlighted innovative design trade-offs, while the web app enabled practical testing.

\subsection{Future Work}
\begin{itemize}
    \item Integrate NAFNet’s channel attention mechanisms.
    \item Train on high-resolution datasets (e.g., DIV2K).
    \item Explore adversarial losses for perceptual quality.
\end{itemize}

\section{References}
\begin{enumerate}
    \item Chen et al., "NAFNet: Nonlinear Activation Free Network for Image Restoration", ECCV 2022. [https://github.com/megvii-research/NAFNet]
    \item Krizhevsky et al., "CIFAR-10 Dataset", 2009.
    \item Ronneberger et al., "U-Net: Convolutional Networks for Biomedical Image Segmentation", MICCAI 2015.
\end{enumerate}

\section{Appendix}
\begin{itemize}
    \item \textbf{Code Repository}: [https://github.com/sandrinjoy/Image-denoising-computer-vision-project-NAFNET] – Includes training scripts and model weights.
    \item \textbf{Hardware}: Trained on Apple M2 Pro and Google Colab CPUs.
    \item \textbf{Ethical Considerations}: Model bias toward CIFAR-10’s classes; smaller models reduce energy consumption.
\end{itemize}

{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
